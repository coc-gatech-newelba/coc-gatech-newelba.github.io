<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.7.3">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2018-04-15T21:49:31-04:00</updated><id>http://localhost:4000/</id><title type="html">Georgia Tech Elba Project</title><subtitle>The Georgia Tech Elba Project page contains a tutorial for how to install and deploy Project Elba's tools for conducting large scale system experiments Our tooling currently supports public cloud infastructures like PRObe and Emulab. We plan to support other infastructures like NSF Cloud and Chameleon in the coming months </subtitle><entry><title type="html">Welcome to Jekyll!</title><link href="http://localhost:4000/jekyll/update/2018/04/11/welcome-to-jekyll.html" rel="alternate" type="text/html" title="Welcome to Jekyll!" /><published>2018-04-11T20:07:21-04:00</published><updated>2018-04-11T20:07:21-04:00</updated><id>http://localhost:4000/jekyll/update/2018/04/11/welcome-to-jekyll</id><content type="html" xml:base="http://localhost:4000/jekyll/update/2018/04/11/welcome-to-jekyll.html">&lt;p&gt;You’ll find this post in your &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run &lt;code class=&quot;highlighter-rouge&quot;&gt;jekyll serve&lt;/code&gt;, which launches a web server and auto-regenerates your site when a file is updated.&lt;/p&gt;

&lt;p&gt;To add new posts, simply add a file in the &lt;code class=&quot;highlighter-rouge&quot;&gt;_posts&lt;/code&gt; directory that follows the convention &lt;code class=&quot;highlighter-rouge&quot;&gt;YYYY-MM-DD-name-of-post.ext&lt;/code&gt; and includes the necessary front matter. Take a look at the source for this post to get an idea about how it works.&lt;/p&gt;

&lt;p&gt;Jekyll also offers powerful support for code snippets:&lt;/p&gt;

&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-ruby&quot; data-lang=&quot;ruby&quot;&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
  &lt;span class=&quot;nb&quot;&gt;puts&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;Hi, &lt;/span&gt;&lt;span class=&quot;si&quot;&gt;#{&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;si&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;s2&quot;&gt;&quot;&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;print_hi&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'Tom'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;#=&amp;gt; prints 'Hi, Tom' to STDOUT.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;

&lt;p&gt;Check out the &lt;a href=&quot;https://jekyllrb.com/docs/home&quot;&gt;Jekyll docs&lt;/a&gt; for more info on how to get the most out of Jekyll. File all bugs/feature requests at &lt;a href=&quot;https://github.com/jekyll/jekyll&quot;&gt;Jekyll’s GitHub repo&lt;/a&gt;. If you have questions, you can ask them on &lt;a href=&quot;https://talk.jekyllrb.com/&quot;&gt;Jekyll Talk&lt;/a&gt;.&lt;/p&gt;</content><author><name></name></author><summary type="html">You’ll find this post in your _posts directory. Go ahead and edit it and re-build the site to see your changes. You can rebuild the site in many different ways, but the most common way is to run jekyll serve, which launches a web server and auto-regenerates your site when a file is updated.</summary></entry><entry><title type="html">Introduction to the Elba Project</title><link href="http://localhost:4000/2018/04/09/introduction-to-the-elba-project.html" rel="alternate" type="text/html" title="Introduction to the Elba Project" /><published>2018-04-09T19:45:23-04:00</published><updated>2018-04-09T19:45:23-04:00</updated><id>http://localhost:4000/2018/04/09/introduction-to-the-elba-project</id><content type="html" xml:base="http://localhost:4000/2018/04/09/introduction-to-the-elba-project.html">&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;~/myblog/pages/2018-03-23-linear-tutorial.html&quot;&gt;Tutorial&lt;/a&gt;   &lt;a class=&quot;button&quot; href=&quot;~/myblog/pages/2018-03-25-faqs.html&quot;&gt;FAQs&lt;/a&gt;&lt;/p&gt;
&lt;p style=&quot;text-align:left;&quot;&gt;&lt;b&gt;Background.&lt;/b&gt; One of the main research challenges in the Adaptive Enterprise vision is the automation of large application system management, encompassing design, deployment, to production use, and capturing application monitoring, evaluation, and evolution. Current approaches to enterprise system evaluation and tuning happen on production systems where the real workload to the deployed system is analyzed on-line and corresponding measurements are taken. In addition, many of these systems go through a detailed staging process that is mostly manual, complex and time-consuming. During the staging process the system to be produced is subjected to workloads to determine whether it will meet the production workloads. Finally, data gleaned from the staging process can be re-used to guide future designs and for management of system during operations.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Project Motivation.&lt;/b&gt; We want to verify and test an application system deployment plan in a staging environment before committing it to a production environment. Manual verification of a deployment is cumbersome, time consuming, and error prone. This problem will grow in importance in the deployment of increasingly larger and more sophisticated applications. Therefore, it will be increasingly important to have an automatic method for executing a benchmark on the deployment plan to validate the deployment during staging, instead of debugging a deployment during production use.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot; size-full wp-image-13 aligncenter&quot; src=&quot;/assets/elba_arch.jpg&quot; alt=&quot;ELBA_ARCH&quot; width=&quot;585&quot; height=&quot;329&quot; /&gt;&lt;/p&gt;
&lt;h2&gt;Contributions and Approaches&lt;/h2&gt;
&lt;h3&gt;Automated Deployment and Staging Infrastructure&lt;/h3&gt;
&lt;p&gt;&lt;b&gt;Approach.&lt;/b&gt; In our project we intend to automate the staging process thus reducing the time and manual labor involved in the process, increase confidence, and extract predictive performance data. Further, the automation will support a more thorough application test and validation in a larger state space, since we plan to automate the monitoring and analysis steps to speed up the refinement of application deployment. Our tools will translate a high-level specification of performance and availability (e.g., SLA requirements) into executable deployment, test, evaluation, and analysis code for the staging phase. This work builds on our experience and technology previously developed such as evaluation of SmartFrog and translation of Quartermaster design specifications into SmartFrog deployment programs.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;System Architecture.&lt;/b&gt; The overall architecture of our project is shown in the figure below, where we achieve full automation in system deployment, evaluation, and evolution, by creating code generation tools to link the different steps of deployment, evaluation, reconfiguration, and redesign in the application deployment lifecycle.&lt;/p&gt;
&lt;h3&gt;Performance Cartography&lt;/h3&gt;
&lt;p&gt;&lt;b&gt;Approach.&lt;/b&gt; In our evaluation, we have created a powerful infrastructure to generate the full set of experimental specifications to measure the performance of standard benchmarks over a wide range of hardware and software configurations. We have decided to use this infrastructure to study experimentally the performance variations of these benchmarks over a range of different configurations. Without our code generation infrastructure, past performance studies have been limited in scope due to practical problems of managing the number of experiments. We have used the Mulini code generator to create a large number of performance measurement experiments, run the experiments and collect/analyze data automatically, and used the analysis to generate Performance Maps.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;System Architecture.&lt;/b&gt; The overall architecture of our project is shown in the figure above, where we achieve full automation in system deployment, evaluation, and evolution, by creating code generation tools to link the different steps of deployment, evaluation, reconfiguration, and redesign in the application deployment lifecycle.&lt;/p&gt;
&lt;p&gt;&lt;b&gt;Research Contributions.&lt;/b&gt; Currently, there is no reliable way to predict the performance of complex applications (e.g., N-Tier distributed application such as Rubis and TPC-App) in a complex environment(e.g., data centers). The limitations of analytical methods are due to the strong assumptions needed for solving the analytical models (e.g., based on queuing theory) that are valid only for relatively simple environments. The limitations of experimental measurements are due to the complexity of managing the many configuration combinations in practice. Our work leverages the Elba infrastructure (particularly, the Mulini generator) to generate and manage the experiments, and then use automated analysis techniques and tools to digest the information and create a Performance Map. The Performance Map is a reliable indicator of complex system performance, since it reflects actually measured experiments on the Performance Terrain (modulo tuning and other complications).&lt;/p&gt;
&lt;h3&gt;Importance of N-Tier Systems&lt;/h3&gt;
&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://gtelbatutorial.wordpress.com/latency-long-tail-problem&quot;&gt;Latency Long Tail Problem&lt;/a&gt;&lt;/p&gt;
&lt;ul style=&quot;font-weight:400;&quot;&gt;
&lt;li&gt;Scalable distributed architecture​
&lt;ul&gt;
&lt;li&gt;Division of labor for low-latency tasks​&lt;/li&gt;
&lt;li&gt;Web servers for parsing/HTML handling​&lt;/li&gt;
&lt;li&gt;App servers for business logic handling​&lt;/li&gt;
&lt;li&gt;DB servers for consistent data management​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Separation of stateless from stateful​
&lt;ul&gt;
&lt;li&gt;DB servers handle the difficult state part​&lt;/li&gt;
&lt;li&gt;Web and App servers are “stateless” so more instances can be easily added, if needed​.&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><author><name>{&quot;login&quot;=&gt;&quot;gtelbaproject&quot;, &quot;email&quot;=&gt;&quot;gt.elba.project@gmail.com&quot;, &quot;display_name&quot;=&gt;&quot;GT Elba Project&quot;, &quot;first_name&quot;=&gt;&quot;GT Elba&quot;, &quot;last_name&quot;=&gt;&quot;Project&quot;}</name><email>gt.elba.project@gmail.com</email></author><summary type="html">Tutorial   FAQs Background. One of the main research challenges in the Adaptive Enterprise vision is the automation of large application system management, encompassing design, deployment, to production use, and capturing application monitoring, evaluation, and evolution. Current approaches to enterprise system evaluation and tuning happen on production systems where the real workload to the deployed system is analyzed on-line and corresponding measurements are taken. In addition, many of these systems go through a detailed staging process that is mostly manual, complex and time-consuming. During the staging process the system to be produced is subjected to workloads to determine whether it will meet the production workloads. Finally, data gleaned from the staging process can be re-used to guide future designs and for management of system during operations. Project Motivation. We want to verify and test an application system deployment plan in a staging environment before committing it to a production environment. Manual verification of a deployment is cumbersome, time consuming, and error prone. This problem will grow in importance in the deployment of increasingly larger and more sophisticated applications. Therefore, it will be increasingly important to have an automatic method for executing a benchmark on the deployment plan to validate the deployment during staging, instead of debugging a deployment during production use. Contributions and Approaches Automated Deployment and Staging Infrastructure Approach. In our project we intend to automate the staging process thus reducing the time and manual labor involved in the process, increase confidence, and extract predictive performance data. Further, the automation will support a more thorough application test and validation in a larger state space, since we plan to automate the monitoring and analysis steps to speed up the refinement of application deployment. Our tools will translate a high-level specification of performance and availability (e.g., SLA requirements) into executable deployment, test, evaluation, and analysis code for the staging phase. This work builds on our experience and technology previously developed such as evaluation of SmartFrog and translation of Quartermaster design specifications into SmartFrog deployment programs. System Architecture. The overall architecture of our project is shown in the figure below, where we achieve full automation in system deployment, evaluation, and evolution, by creating code generation tools to link the different steps of deployment, evaluation, reconfiguration, and redesign in the application deployment lifecycle. Performance Cartography Approach. In our evaluation, we have created a powerful infrastructure to generate the full set of experimental specifications to measure the performance of standard benchmarks over a wide range of hardware and software configurations. We have decided to use this infrastructure to study experimentally the performance variations of these benchmarks over a range of different configurations. Without our code generation infrastructure, past performance studies have been limited in scope due to practical problems of managing the number of experiments. We have used the Mulini code generator to create a large number of performance measurement experiments, run the experiments and collect/analyze data automatically, and used the analysis to generate Performance Maps. System Architecture. The overall architecture of our project is shown in the figure above, where we achieve full automation in system deployment, evaluation, and evolution, by creating code generation tools to link the different steps of deployment, evaluation, reconfiguration, and redesign in the application deployment lifecycle. Research Contributions. Currently, there is no reliable way to predict the performance of complex applications (e.g., N-Tier distributed application such as Rubis and TPC-App) in a complex environment(e.g., data centers). The limitations of analytical methods are due to the strong assumptions needed for solving the analytical models (e.g., based on queuing theory) that are valid only for relatively simple environments. The limitations of experimental measurements are due to the complexity of managing the many configuration combinations in practice. Our work leverages the Elba infrastructure (particularly, the Mulini generator) to generate and manage the experiments, and then use automated analysis techniques and tools to digest the information and create a Performance Map. The Performance Map is a reliable indicator of complex system performance, since it reflects actually measured experiments on the Performance Terrain (modulo tuning and other complications). Importance of N-Tier Systems Latency Long Tail Problem Scalable distributed architecture​ Division of labor for low-latency tasks​ Web servers for parsing/HTML handling​ App servers for business logic handling​ DB servers for consistent data management​ Separation of stateless from stateful​ DB servers handle the difficult state part​ Web and App servers are “stateless” so more instances can be easily added, if needed​.</summary></entry><entry><title type="html">Tutorial</title><link href="http://localhost:4000/2018/04/09/tutorial-2.html" rel="alternate" type="text/html" title="Tutorial" /><published>2018-04-09T19:45:03-04:00</published><updated>2018-04-09T19:45:03-04:00</updated><id>http://localhost:4000/2018/04/09/tutorial-2</id><content type="html" xml:base="http://localhost:4000/2018/04/09/tutorial-2.html">&lt;p&gt;This tutorial is split into three main sections which are set-up, experiment generation, and experiment execution. If doing this tutorial for the first time please start from set-up and follow in chronological order.&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://gtelbatutorial.wordpress.com/set-up/&quot;&gt;Set-Up&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Set-up will take the user through creating an Emulab account, generating a SSH key, and creating the correct directories in which to run the experiment.&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://gtelbatutorial.wordpress.com/experiment-generation/&quot;&gt;Experiment Generation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The experiment generation section will take the user through creating the experiment, describing the experiment topology in the xml file, assigning parameters, and generating the script and code needed for the experiment.&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;https://gtelbatutorial.wordpress.com/Experiment-Execution/&quot;&gt;Experiment Execution&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;The experiment execution section will take the user through the actual execution of the experiment and the user can then go to our &lt;a href=&quot;https://gtelbatutorial.wordpress.com/experiment-analysis/&quot;&gt;analysis section&lt;/a&gt; to properly analyze their results.&lt;/p&gt;</content><author><name>{&quot;login&quot;=&gt;&quot;gtelbaproject&quot;, &quot;email&quot;=&gt;&quot;gt.elba.project@gmail.com&quot;, &quot;display_name&quot;=&gt;&quot;GT Elba Project&quot;, &quot;first_name&quot;=&gt;&quot;GT Elba&quot;, &quot;last_name&quot;=&gt;&quot;Project&quot;}</name><email>gt.elba.project@gmail.com</email></author><summary type="html">This tutorial is split into three main sections which are set-up, experiment generation, and experiment execution. If doing this tutorial for the first time please start from set-up and follow in chronological order. Set-Up Set-up will take the user through creating an Emulab account, generating a SSH key, and creating the correct directories in which to run the experiment. Experiment Generation The experiment generation section will take the user through creating the experiment, describing the experiment topology in the xml file, assigning parameters, and generating the script and code needed for the experiment. Experiment Execution The experiment execution section will take the user through the actual execution of the experiment and the user can then go to our analysis section to properly analyze their results.</summary></entry><entry><title type="html">Experiment Customization</title><link href="http://localhost:4000/2018/04/09/experiment-creation.html" rel="alternate" type="text/html" title="Experiment Customization" /><published>2018-04-09T19:44:48-04:00</published><updated>2018-04-09T19:44:48-04:00</updated><id>http://localhost:4000/2018/04/09/experiment-creation</id><content type="html" xml:base="http://localhost:4000/2018/04/09/experiment-creation.html">&lt;p&gt;To increase the efficiency and speed of cloud-based systems research, we rely on code generation techniques to create experiments. Before generating artifacts such as installation scripts and configuration, a &quot;reservation&quot; needs to be created on one of the supported public clouds. In addition, the experiment configuration needs to be supplied to the generator. The following two steps accomplish these tasks while the final step outputs the necessary experimental artifacts for running the desired experiment on the public cloud.&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;myblog/_pages/2018-03-23-experiment-customization.html&quot;&gt;Experiment Customization&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;myblog/_pages/2018-03-23-experiment-topology-1-1-1-1.html&quot;&gt;1-1-1-1&lt;/a&gt;   &lt;a class=&quot;button&quot; href=&quot;myblog/_pages/2018-03-23-experiment-topology-1-1-1-1.html&quot;&gt;1-1-1-2&lt;/a&gt;   &lt;a class=&quot;button&quot; href=&quot;myblog/_pages/2018-03-23-experiment-topology-1-1-1-1.html&quot;&gt;1-1-1-3&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a class=&quot;button&quot; href=&quot;myblog/_pages/2018-03-23-experiment-topology-1-1-1-1.html/&quot;&gt;1-1-1-4&lt;/a&gt;   &lt;a class=&quot;button&quot; href=&quot;myblog/_pages/2018-03-23-experiment-topology-1-1-1-1.html&quot;&gt;1-1-1-5&lt;/a&gt;   &lt;a class=&quot;button&quot; href=&quot;myblog/_pages/2018-03-23-experiment-topology-1-1-1-1.html/&quot;&gt;1-1-1-6&lt;/a&gt;&lt;/p&gt;</content><author><name>{&quot;login&quot;=&gt;&quot;gtelbaproject&quot;, &quot;email&quot;=&gt;&quot;gt.elba.project@gmail.com&quot;, &quot;display_name&quot;=&gt;&quot;GT Elba Project&quot;, &quot;first_name&quot;=&gt;&quot;GT Elba&quot;, &quot;last_name&quot;=&gt;&quot;Project&quot;}</name><email>gt.elba.project@gmail.com</email></author><summary type="html">To increase the efficiency and speed of cloud-based systems research, we rely on code generation techniques to create experiments. Before generating artifacts such as installation scripts and configuration, a &quot;reservation&quot; needs to be created on one of the supported public clouds. In addition, the experiment configuration needs to be supplied to the generator. The following two steps accomplish these tasks while the final step outputs the necessary experimental artifacts for running the desired experiment on the public cloud. Experiment Customization 1-1-1-1   1-1-1-2   1-1-1-3 1-1-1-4   1-1-1-5   1-1-1-6</summary></entry><entry><title type="html">Tools and Instrumentation</title><link href="http://localhost:4000/2018/04/09/tools-2.html" rel="alternate" type="text/html" title="Tools and Instrumentation" /><published>2018-04-09T19:44:08-04:00</published><updated>2018-04-09T19:44:08-04:00</updated><id>http://localhost:4000/2018/04/09/tools-2</id><content type="html" xml:base="http://localhost:4000/2018/04/09/tools-2.html">&lt;h4&gt;milliMonitor&lt;/h4&gt;
&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-104&quot; src=&quot;/assets/screen-shot-2018-03-28-at-7-07-24-pm.png&quot; alt=&quot;Screen Shot 2018-03-28 at 7.07.24 PM&quot; width=&quot;818&quot; height=&quot;434&quot; /&gt;&lt;/p&gt;
&lt;ul style=&quot;font-weight:400;&quot;&gt;
&lt;li&gt;Each component aligns with one of the phases of our pipeline​&lt;/li&gt;
&lt;li&gt;Generate Experiment – specifying an experiment and generating artifacts​&lt;/li&gt;
&lt;li&gt;Execute Experiment – automatically provisioning a cloud and deploying the artifacts​&lt;/li&gt;
&lt;li&gt;Analyze Experimental Data – automatically collecting, parsing and reasoning over the data​&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;milliMonitor High Level Design&lt;/h4&gt;
&lt;ul style=&quot;font-weight:400;&quot;&gt;
&lt;li&gt;Templates &amp;amp; Script Generator​
&lt;ul&gt;
&lt;li&gt;Aspect-oriented code generator​&lt;/li&gt;
&lt;li&gt;Specializes scripts, benchmark source code and configuration using XML-based spec.​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;mScope Monitors​
&lt;ul&gt;
&lt;li&gt;Inject measurement schema into benchmark​&lt;/li&gt;
&lt;li&gt;Record identifier, timestamps and output in native benchmark logs​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;mScope Data Transformer, mScope DB​
&lt;ul&gt;
&lt;li&gt;Ingest and normalize data from mScope monitors​&lt;/li&gt;
&lt;li&gt;Dynamic database to persist transformed data​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;milliAnalyst​
&lt;ul&gt;
&lt;li&gt;Combines known millibottleneck mechanisms with data​&lt;/li&gt;
&lt;li&gt;Reduces millibottleneck identification and root cause isolation / determination into a longest path problem&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;mScopeMonitors&lt;/h4&gt;
&lt;ul style=&quot;font-weight:400;&quot;&gt;
&lt;li&gt;Currently, we have implemented Apache, Tomcat, CJDBC, and Nginx event mScopeMonitors ​&lt;/li&gt;
&lt;li&gt;Each event mScopeMonitor records four timestamps for each request on each component, which can be used to rebuild the causal relationship.​&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-206&quot; src=&quot;/assets/screen-shot-2018-04-09-at-4-05-33-pm.png&quot; alt=&quot;Screen Shot 2018-04-09 at 4.05.33 PM&quot; width=&quot;557&quot; height=&quot;381&quot; /&gt;&lt;/p&gt;
&lt;ul style=&quot;font-weight:400;&quot;&gt;
&lt;li&gt;Collectl: A monitor tool capable of recording system resource utilization, including CPU, memory, process runtime state, network and disk I/O at fine granularity (every 50ms).​&lt;/li&gt;
&lt;li&gt;SAR: collects, reports and saves system activity information (CPU, memory, disks, interrupts, network interfaces, TTY, kernel tables,etc.)​&lt;/li&gt;
&lt;li&gt;IOStat: reports CPU statistics and input/output statistics for devices, partitions and network filesystems.​&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Event Monitors and Resource Monitors&lt;/h4&gt;
&lt;h4&gt;milliAnalyst&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Uniform data interface consisting of three entities:​
&lt;ul&gt;
&lt;li&gt;PointinTime ​&lt;/li&gt;
&lt;li&gt;DownstreamServiceTime (DST)​&lt;/li&gt;
&lt;li&gt;ResourceObservations​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Each of these entities can have a variable number of number of attributes ​&lt;/li&gt;
&lt;li&gt;Experiment specification impacts this, i.e. the number of nodes determines the number of DST attributes​&lt;/li&gt;
&lt;li&gt;Number of attributes can also depend on characteristics that might not be known prior to running an experiment, such as a node’s number of CPUs, cores, NICs or disks​&lt;/li&gt;
&lt;li&gt;Method needs to handle this variable number of attributes, i.e. no fixed schemas​&lt;/li&gt;
&lt;li&gt;Method needs to be able to integrate data across time and space​&lt;/li&gt;
&lt;li&gt;Representation needs to be able to handle data anomalies and support efficient filtering and retrieval of small data subsets across all of the measurements​&lt;/li&gt;
&lt;li&gt;Support graph-based reasoning​&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Cloud Deployment&lt;/h4&gt;</content><author><name>{&quot;login&quot;=&gt;&quot;gtelbaproject&quot;, &quot;email&quot;=&gt;&quot;gt.elba.project@gmail.com&quot;, &quot;display_name&quot;=&gt;&quot;GT Elba Project&quot;, &quot;first_name&quot;=&gt;&quot;GT Elba&quot;, &quot;last_name&quot;=&gt;&quot;Project&quot;}</name><email>gt.elba.project@gmail.com</email></author><summary type="html">milliMonitor Each component aligns with one of the phases of our pipeline​ Generate Experiment – specifying an experiment and generating artifacts​ Execute Experiment – automatically provisioning a cloud and deploying the artifacts​ Analyze Experimental Data – automatically collecting, parsing and reasoning over the data​ milliMonitor High Level Design Templates &amp;amp; Script Generator​ Aspect-oriented code generator​ Specializes scripts, benchmark source code and configuration using XML-based spec.​ mScope Monitors​ Inject measurement schema into benchmark​ Record identifier, timestamps and output in native benchmark logs​ mScope Data Transformer, mScope DB​ Ingest and normalize data from mScope monitors​ Dynamic database to persist transformed data​ milliAnalyst​ Combines known millibottleneck mechanisms with data​ Reduces millibottleneck identification and root cause isolation / determination into a longest path problem mScopeMonitors Currently, we have implemented Apache, Tomcat, CJDBC, and Nginx event mScopeMonitors ​ Each event mScopeMonitor records four timestamps for each request on each component, which can be used to rebuild the causal relationship.​ Collectl: A monitor tool capable of recording system resource utilization, including CPU, memory, process runtime state, network and disk I/O at fine granularity (every 50ms).​ SAR: collects, reports and saves system activity information (CPU, memory, disks, interrupts, network interfaces, TTY, kernel tables,etc.)​ IOStat: reports CPU statistics and input/output statistics for devices, partitions and network filesystems.​ Event Monitors and Resource Monitors milliAnalyst Uniform data interface consisting of three entities:​ PointinTime ​ DownstreamServiceTime (DST)​ ResourceObservations​ Each of these entities can have a variable number of number of attributes ​ Experiment specification impacts this, i.e. the number of nodes determines the number of DST attributes​ Number of attributes can also depend on characteristics that might not be known prior to running an experiment, such as a node’s number of CPUs, cores, NICs or disks​ Method needs to handle this variable number of attributes, i.e. no fixed schemas​ Method needs to be able to integrate data across time and space​ Representation needs to be able to handle data anomalies and support efficient filtering and retrieval of small data subsets across all of the measurements​ Support graph-based reasoning​ Cloud Deployment</summary></entry><entry><title type="html">Data Processing and Management</title><link href="http://localhost:4000/2018/04/09/data-processing-and-management-2.html" rel="alternate" type="text/html" title="Data Processing and Management" /><published>2018-04-09T19:43:24-04:00</published><updated>2018-04-09T19:43:24-04:00</updated><id>http://localhost:4000/2018/04/09/data-processing-and-management-2</id><content type="html" xml:base="http://localhost:4000/2018/04/09/data-processing-and-management-2.html">&lt;h4&gt;milliScope Data Flow and Architecture&lt;/h4&gt;
&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-103&quot; src=&quot;/assets/screen-shot-2018-03-28-at-7-05-35-pm.png&quot; alt=&quot;Screen Shot 2018-03-28 at 7.05.35 PM&quot; width=&quot;868&quot; height=&quot;373&quot; /&gt;&lt;/p&gt;
&lt;p&gt;The data transformation flow of milliScope. The event mScopeMonitors capture&lt;br /&gt;
timestamps, as shown in Figure 4, in the component logs, while the resource mScopeMonitors record the system resource utilization. mScopeDataTranformer converts these unstructured data to structured tuples and loads them into a dynamic data warehouse, mScopeDB, for advanced analysis.&lt;/p&gt;
&lt;h6&gt;mScopeData Transformer Design&lt;/h6&gt;
&lt;ul&gt;
&lt;li style=&quot;list-style-type:none;&quot;&gt;
&lt;ul&gt;
&lt;li&gt;Data pipeline transforms highly variable monitoring data into aggregates that are helpful in millibottleneck isolation and root cause analysis​&lt;/li&gt;
&lt;li&gt;These aggregates are:​
&lt;ul&gt;
&lt;li&gt;Point-in-Time Response Time​&lt;/li&gt;
&lt;li&gt;Queue Length​&lt;/li&gt;
&lt;li&gt;Downstream Service Time​&lt;/li&gt;
&lt;li&gt;Resource Consumption Descriptive Statistics​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h6&gt;Other Parsers&lt;/h6&gt;
&lt;p&gt;&amp;nbsp;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Parsers – extract request-level data out of component logs.
&lt;ul&gt;
&lt;li&gt;ServiceTime – reads request-level data and calculates dst​&lt;/li&gt;
&lt;li&gt;Pointintime – reads request-level data (Apache) and calculated pit​&lt;/li&gt;
&lt;li&gt;Multifile – basically joins and aggregates data in uniform entities (dst_table, resource_table); pit is independent​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;How to reconcile not ingesting XML into mScopeDataTransformer?​
&lt;ul&gt;
&lt;li&gt;Component parsers were supposed to output XML​&lt;/li&gt;
&lt;li&gt;Even if they were, we still need to calculate aggregates like queue lengths and dst​
&lt;ul&gt;
&lt;li&gt;Prob in database; the issue with this is trying to do the integration and calculation when the schemas change…​&lt;/li&gt;
&lt;li&gt;Or, compute aggregates externally and import​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><author><name>{&quot;login&quot;=&gt;&quot;gtelbaproject&quot;, &quot;email&quot;=&gt;&quot;gt.elba.project@gmail.com&quot;, &quot;display_name&quot;=&gt;&quot;GT Elba Project&quot;, &quot;first_name&quot;=&gt;&quot;GT Elba&quot;, &quot;last_name&quot;=&gt;&quot;Project&quot;}</name><email>gt.elba.project@gmail.com</email></author><summary type="html">milliScope Data Flow and Architecture The data transformation flow of milliScope. The event mScopeMonitors capture timestamps, as shown in Figure 4, in the component logs, while the resource mScopeMonitors record the system resource utilization. mScopeDataTranformer converts these unstructured data to structured tuples and loads them into a dynamic data warehouse, mScopeDB, for advanced analysis. mScopeData Transformer Design Data pipeline transforms highly variable monitoring data into aggregates that are helpful in millibottleneck isolation and root cause analysis​ These aggregates are:​ Point-in-Time Response Time​ Queue Length​ Downstream Service Time​ Resource Consumption Descriptive Statistics​ Other Parsers &amp;nbsp; Parsers – extract request-level data out of component logs. ServiceTime – reads request-level data and calculates dst​ Pointintime – reads request-level data (Apache) and calculated pit​ Multifile – basically joins and aggregates data in uniform entities (dst_table, resource_table); pit is independent​ How to reconcile not ingesting XML into mScopeDataTransformer?​ Component parsers were supposed to output XML​ Even if they were, we still need to calculate aggregates like queue lengths and dst​ Prob in database; the issue with this is trying to do the integration and calculation when the schemas change…​ Or, compute aggregates externally and import​</summary></entry><entry><title type="html">Methodology and Data Analysis</title><link href="http://localhost:4000/2018/04/09/methodology-and-data-analysis.html" rel="alternate" type="text/html" title="Methodology and Data Analysis" /><published>2018-04-09T19:43:05-04:00</published><updated>2018-04-09T19:43:05-04:00</updated><id>http://localhost:4000/2018/04/09/methodology-and-data-analysis</id><content type="html" xml:base="http://localhost:4000/2018/04/09/methodology-and-data-analysis.html">&lt;h4&gt;Analysis Outline&lt;/h4&gt;
&lt;ol&gt;
&lt;li&gt;Explain your approach to data transformation, integration, and management.&lt;/li&gt;
&lt;li&gt;Detail how you use the data gathered to isolate millibottlenecks and diagnose their root cause.&lt;/li&gt;
&lt;li&gt;Describe the steps needed to analyze your experiment:
&lt;ol&gt;
&lt;li&gt;Copy the tarball archive containing the experiment data to a location proximate to the cloned Elba Github repository.&lt;/li&gt;
&lt;li&gt;Unzip the copied archive.&lt;/li&gt;
&lt;li&gt;Navigate to the parsers directory of the cloned Elba Github repository.&lt;/li&gt;
&lt;li&gt;Execute &quot;runparsers.sh&quot; by providing the following:
&lt;ol&gt;
&lt;li&gt;Path to the directory containing the unzipped archive&lt;/li&gt;
&lt;li&gt;Target location to store the processing results&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h4&gt;milliAnalyst&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Uniform data interface consisting of three entities:​
&lt;ul&gt;
&lt;li&gt;PointinTime ​&lt;/li&gt;
&lt;li&gt;DownstreamServiceTime (DST)​&lt;/li&gt;
&lt;li&gt;ResourceObservations​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Each of these entities can have a variable number of number of attributes ​&lt;/li&gt;
&lt;li&gt;Experiment specification impacts this, i.e. the number of nodes determines the number of DST attributes​&lt;/li&gt;
&lt;li&gt;Number of attributes can also depend on characteristics that might not be known prior to running an experiment, such as a node’s number of CPUs, cores, NICs or disks​&lt;/li&gt;
&lt;li&gt;Method needs to handle this variable number of attributes, i.e. no fixed schemas​&lt;/li&gt;
&lt;li&gt;Method needs to be able to integrate data across time and space​&lt;/li&gt;
&lt;li&gt;Representation needs to be able to handle data anomalies and support efficient filtering and retrieval of small data subsets across all of the measurements​&lt;/li&gt;
&lt;li&gt;Support graph-based reasoning​&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;milliBottlenecks&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Millibottlenecks happen in different system layers​
&lt;ul&gt;
&lt;li&gt;System software: Java garbage collection​&lt;/li&gt;
&lt;li&gt;Processor architecture: DVFS​&lt;/li&gt;
&lt;li&gt;Application Virtual Machine consolidation​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Though short-lived, millibottlenecks have big impact&lt;b&gt; &lt;/b&gt;on n-tier application performance​
&lt;ul&gt;
&lt;li&gt;VLRT requests​&lt;/li&gt;
&lt;li&gt;Queue amplification from n-tier system component dependencies​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img class=&quot;alignnone size-full wp-image-104&quot; src=&quot;/assets/screen-shot-2018-03-28-at-7-07-24-pm.png&quot; alt=&quot;Screen Shot 2018-03-28 at 7.07.24 PM&quot; width=&quot;818&quot; height=&quot;434&quot; /&gt;&lt;/p&gt;
&lt;p&gt;Above is the work flow of milliBottleneck discovery. Users define the configuration file at first, and the script generator generates scripts which set up the experiment environment and deploy milliScope as well as other softwares. mScopeDataTransformer converts these unstructured data to structured tuples in mScopeDB as described in Figure 3 for advanced analysis.&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot; size-full wp-image-216 aligncenter&quot; src=&quot;/assets/screen-shot-2018-04-10-at-12-39-26-pm.png&quot; alt=&quot;Screen Shot 2018-04-10 at 12.39.26 PM&quot; width=&quot;475&quot; height=&quot;596&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;VLRT requests (see (a)) caused by queue peaks in Apache (see (b)) when the system is at workload 9000 clients.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img class=&quot;  wp-image-215 aligncenter&quot; src=&quot;/assets/screen-shot-2018-04-10-at-12-39-49-pm.png&quot; alt=&quot;Screen Shot 2018-04-10 at 12.39.49 PM&quot; width=&quot;381&quot; height=&quot;728&quot; /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Queue peaks in Apache (a) due to very short bottlenecks caused by Java GC in Tomcat (d).&lt;/li&gt;
&lt;/ul&gt;
&lt;h4&gt;Solutions&lt;/h4&gt;
&lt;ul&gt;
&lt;li&gt;Three kinds of solutions for Latency Long Tail Problem​
&lt;ul&gt;
&lt;li&gt;Bug-fix, specific solutions for each cause (many causes, not all can be fixed)​&lt;/li&gt;
&lt;li&gt;General solutions for transient bottlenecks (primarily improved queue management)​&lt;/li&gt;
&lt;li&gt;Last-resort solution​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Bug-Fix for Specific Solutions
&lt;ul&gt;
&lt;li&gt;Some cases can be “fixed”​
&lt;ul&gt;
&lt;li&gt;Java GC in JVM 1.5 was “fixed” in JVM 1.6​&lt;/li&gt;
&lt;li&gt;DVFS anti-synchrony can be “fixed” by changing control periods (some complications)​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Other cases are harder to fix​
&lt;ul&gt;
&lt;li&gt;VM consolidation case (noisy neighbor) is really non-deterministic​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Kernel daemon processes (many)​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;General Solutions
&lt;ul&gt;
&lt;li&gt;Approaches that address transient bottlenecks (instead of specific “bugs”)​
&lt;ul&gt;
&lt;li&gt;3 stages: (1) transient bottleneck formation, (2) queue amplification, (3) packet retransmission​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;(1) Transient bottleneck detection and remedial action (e.g., disruption)​
&lt;ul&gt;
&lt;li&gt;Difficult, due to the short lifespan of transient bottlenecks​&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;</content><author><name>{&quot;login&quot;=&gt;&quot;gtelbaproject&quot;, &quot;email&quot;=&gt;&quot;gt.elba.project@gmail.com&quot;, &quot;display_name&quot;=&gt;&quot;GT Elba Project&quot;, &quot;first_name&quot;=&gt;&quot;GT Elba&quot;, &quot;last_name&quot;=&gt;&quot;Project&quot;}</name><email>gt.elba.project@gmail.com</email></author><summary type="html">Analysis Outline Explain your approach to data transformation, integration, and management. Detail how you use the data gathered to isolate millibottlenecks and diagnose their root cause. Describe the steps needed to analyze your experiment: Copy the tarball archive containing the experiment data to a location proximate to the cloned Elba Github repository. Unzip the copied archive. Navigate to the parsers directory of the cloned Elba Github repository. Execute &quot;runparsers.sh&quot; by providing the following: Path to the directory containing the unzipped archive Target location to store the processing results milliAnalyst Uniform data interface consisting of three entities:​ PointinTime ​ DownstreamServiceTime (DST)​ ResourceObservations​ Each of these entities can have a variable number of number of attributes ​ Experiment specification impacts this, i.e. the number of nodes determines the number of DST attributes​ Number of attributes can also depend on characteristics that might not be known prior to running an experiment, such as a node’s number of CPUs, cores, NICs or disks​ Method needs to handle this variable number of attributes, i.e. no fixed schemas​ Method needs to be able to integrate data across time and space​ Representation needs to be able to handle data anomalies and support efficient filtering and retrieval of small data subsets across all of the measurements​ Support graph-based reasoning​ milliBottlenecks Millibottlenecks happen in different system layers​ System software: Java garbage collection​ Processor architecture: DVFS​ Application Virtual Machine consolidation​ Though short-lived, millibottlenecks have big impact on n-tier application performance​ VLRT requests​ Queue amplification from n-tier system component dependencies​ Above is the work flow of milliBottleneck discovery. Users define the configuration file at first, and the script generator generates scripts which set up the experiment environment and deploy milliScope as well as other softwares. mScopeDataTransformer converts these unstructured data to structured tuples in mScopeDB as described in Figure 3 for advanced analysis. VLRT requests (see (a)) caused by queue peaks in Apache (see (b)) when the system is at workload 9000 clients. Queue peaks in Apache (a) due to very short bottlenecks caused by Java GC in Tomcat (d). Solutions Three kinds of solutions for Latency Long Tail Problem​ Bug-fix, specific solutions for each cause (many causes, not all can be fixed)​ General solutions for transient bottlenecks (primarily improved queue management)​ Last-resort solution​ Bug-Fix for Specific Solutions Some cases can be “fixed”​ Java GC in JVM 1.5 was “fixed” in JVM 1.6​ DVFS anti-synchrony can be “fixed” by changing control periods (some complications)​ Other cases are harder to fix​ VM consolidation case (noisy neighbor) is really non-deterministic​ Kernel daemon processes (many)​ General Solutions Approaches that address transient bottlenecks (instead of specific “bugs”)​ 3 stages: (1) transient bottleneck formation, (2) queue amplification, (3) packet retransmission​ (1) Transient bottleneck detection and remedial action (e.g., disruption)​ Difficult, due to the short lifespan of transient bottlenecks​</summary></entry><entry><title type="html">Publications</title><link href="http://localhost:4000/2018/04/09/publications.html" rel="alternate" type="text/html" title="Publications" /><published>2018-04-09T19:42:03-04:00</published><updated>2018-04-09T19:42:03-04:00</updated><id>http://localhost:4000/2018/04/09/publications</id><content type="html" xml:base="http://localhost:4000/2018/04/09/publications.html">&lt;h2&gt;2017&lt;/h2&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Qingyang Wang, Chien-An Lai, Yasuhiko Kanemasa, Shungeng Zhang, and Calton Pu &lt;/span&gt;&lt;/strong&gt;“A Study of Long-Tail Latency in n-Tier Systems: RPC vs. Asynchronous Invocations”, In &lt;em&gt;37th International Conference on Distributed Computing Systems (ICDCS'17), Atlanta, GA, June 2017. (Acceptance rate: 90/531=16.9%)&lt;/em&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Chien-An Lai, Joshua Kimball, Tao Zhu, Qingyang Wang, and Calton Pu&lt;/span&gt;&lt;/strong&gt;“milliScope: a Fine-Grained Monitoring Framework for Performance Debugging of n-Tier Web Services&quot;, In &lt;em&gt;37th International Conference on Distributed Computing Systems (ICDCS'17), Atlanta, GA, June 2017. (Acceptance rate: 90/531=16.9%)&lt;/em&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Tao Zhu, Jack Li, Josh Kimball, Junhee Park, Chien-An Lai, Calton Pu and Qingyang Wang &lt;/span&gt;&lt;/strong&gt;&quot;Limitations of Load Balancing Mechanisms for N-Tier Systems in the Presence of Millibottlenecks&quot;, In &lt;em&gt;37th International Conference on Distributed Computing Systems (ICDCS'17), Atlanta, GA, June 2017. (Application track)&lt;/em&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2016&lt;/h2&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Junhee Park, Qingyang Wang Jack Li, Chien-An Lai, Tao Zhu, Calton Pu&lt;/span&gt;&lt;/strong&gt;“Performance Interference of Memory Thrashing in Virtualized Cloud Environments: A Study of consolidated n-Tier Applications”, In &lt;em&gt;Proc. of the 9th International Conference On Cloud Computing (Cloud'16). (Acceptance rate: 15%) (Runner-Up for Best Paper Award)&lt;/em&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2015&lt;/h2&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Jack Li, Yuan Chen, Vanish Talwar, Calton Pu, Dejan Milojicic, &lt;/span&gt;&lt;/strong&gt;&quot;Improving Preemptive Scheduling with Application-Transparent Checkpointing in Shared Clusters&quot;, In &lt;em&gt;Middleware 2015.&lt;/em&gt; [tbd]&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2014&lt;/h2&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Jack Li, Qingyang Wang, Chien-An Lai, Junhee Park, Daisuke Yokoyama, Calton Pu, &lt;/span&gt;&lt;/strong&gt;&quot;The Impact of Software Resource Allocation on Consolidated n-Tier Applications&quot;, In &lt;em&gt;CLOUD 2014.&lt;/em&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Qingyang Wang, Jack Li, Chien-An Lai, Chien-An Cho, Yuji Nomura, Calton Pu&lt;/span&gt;&lt;/strong&gt;&quot;Lightning in the Cloud: A Study of Transient Bottlenecks on n-Tier Web Application Performance&quot;, In &lt;em&gt;TRIOS 2014.&lt;/em&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Chien-An Lai, Qingyang Wang, Josh Kimball, Jack Li, Junhee Park, Calton Pu, &lt;/span&gt;&lt;/strong&gt;&quot;IO Performance Interference among Consolidated n-Tier Applications: Sharing Is Better Than Isolation for Disks&quot;, In &lt;em&gt;CLOUD 2014.&lt;/em&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2013&lt;/h2&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Qingyang Wang, Yasuhiko Kanemasa, Jack Li, Chien An Lai, Masazumi Matsubara, Calton Pu, &lt;/span&gt;&lt;/strong&gt;&quot;Impact of DVFS on n-Tier Application Performance&quot;, In Proc. of ACM Conference on Timely Results in Operating Systems (&lt;strong&gt;TRIOS'13&lt;/strong&gt;), Nemacolin Woodlands Resort, Farmington, Pennsylvania, November 2013. &lt;a href=&quot;http://www-static.cc.gatech.edu/~qywang/papers/TRIOS13-Qingyang.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Qingyang Wang, Yasuhiko Kanemasa, Jack Li, Deepal Jayasinghe, Toshihiro Shimizu, Masazumi Matsubara, Motoyuki Kawaba, Calton Pu. &lt;/span&gt;&lt;/strong&gt;&quot;Detecting Transient Bottlenecks in n-Tier Applications through Fine-Grained Analysis&quot;, In &lt;em&gt;ICDCS 2013.&lt;/em&gt;&lt;a href=&quot;http://www.cc.gatech.edu/systems/projects/Elba/pub/ICDCS13Wang.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Qingyang Wang, Yasuhiko Kanemasa, Jack Li, Deepal Jayasinghe, Toshihiro Shimizu, Masazumi Matsubara, Motoyuki Kawaba, Calton Pu. &lt;/span&gt;&lt;/strong&gt;&quot;An Experimental Study of Rapidly Alternating Bottlenecks in n-Tier Applications&quot;, In &lt;em&gt;Cloud 2013.&lt;/em&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;(Runner-Up for Best Student Paper Award).&lt;/span&gt;&lt;/strong&gt;&lt;a href=&quot;http://www.cc.gatech.edu/systems/projects/Elba/pub/Cloud13Wang.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Deepal Jayasinghe, Fabio Oliveira, Florian Rosenberg, Tamar Eilam, Calton Pu. &lt;/span&gt;&lt;/strong&gt;&quot;AESON: A Model-Driven and Fault Tolerant Composite Deployment Runtime for IaaS Clouds&quot;, In &lt;em&gt;SCC 2013.&lt;/em&gt;&lt;a href=&quot;http://www.cc.gatech.edu/systems/projects/Elba/pub/ieee-scc-Deepal13.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Deepal Jayasinghe, Josh Kimball, Tao Zhu, Siddharth Choudhary, Calton Pu. &lt;/span&gt;&lt;/strong&gt;&quot;An Infrastructure for Automating Large-scale Performance Studies and Data Processing&quot;, In &lt;em&gt;BigData 2013.&lt;/em&gt;&lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/bigdata.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Deepal Jayasinghe, Josh Kimball, Siddharth Choudhary, Tao Zhu, Calton Pu. &lt;/span&gt;&lt;/strong&gt;&quot;An Automated Approach to Create, Store, and Analyze Large-scale Experimental Data in Clouds&quot;, In &lt;em&gt;IRI 2013.&lt;/em&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;(Best Student Paper Award).&lt;/span&gt;&lt;/strong&gt;&lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/iri.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Junhee Park, Qingyang Wang, Deepal Jayasinghe, Jack Li, Yasuhiko Kanemasa, Masazumi Matsubara, Calton Pu. &lt;/span&gt;&lt;/strong&gt;&quot;Variations in Performance Measurements of Multi-Core Processors: A Study of n-Tier Applications&quot;, In &lt;em&gt;SCC 2013.&lt;/em&gt;&lt;a href=&quot;http://www.cc.gatech.edu/systems/projects/Elba/pub/jpark_5982_SCC13.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Jack Li, Qingyang Wang, Deepal Jayasinghe, Junhee Park, Tao Zhu, Calton Pu. &lt;/span&gt;&lt;/strong&gt;&quot;Performance Overhead Among Three Hypervisors: An Experimental Study using Hadoop Benchmarks&quot;, In &lt;em&gt;BigData Congress 2013.&lt;/em&gt;&lt;a href=&quot;http://www.cc.gatech.edu/systems/projects/Elba/pub/JackLiBigdata13.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Yasuhiko Kanemasa, Qingyang Wang, Jack Li, Masazumi Matsubara, Calton Pu. &lt;/span&gt;&lt;/strong&gt;&quot;Revisiting Performance Interference among Consolidated n-Tier Applications: Sharing is Better than Isolation&quot;, In &lt;em&gt;SCC 2013.&lt;/em&gt;&lt;a href=&quot;http://www.cc.gatech.edu/systems/projects/Elba/pub/scc2013-VMcollocation.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2012&lt;/h2&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Qingyang Wang, Yasuhiko Kanemasa, Motoyuki Kawaba, Calton Pu.&lt;/span&gt;&lt;/strong&gt;&quot;When Average is Not Average: Large Response Time Fluctuations in n-Tier Systems&quot;, In &lt;em&gt;ICAC 2012.&lt;/em&gt;&lt;a href=&quot;http://www-static.cc.gatech.edu/~qywang/papers/ICAC12Wang.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Qingyang Wang, Yasuhiko Kanemasa, Jack Li, Deepal Jayasinghe, Motoyuki Kawaba, Calton Pu&lt;/span&gt;&lt;/strong&gt;&quot;Response Time Reliability in Cloud Environments: An Empirical Study of n-Tier Applications at High Resource Utilization&quot;, In &lt;em&gt;SRDS 2012.&lt;/em&gt;&lt;a href=&quot;http://www-static.cc.gatech.edu/~qywang/papers/SRDS12Wang.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Deepal Jayasinghe, Galen Swint, Simon Malkowski, Jack Li, Qingyang Wang, Junhee Park and Calton Pu.&lt;/span&gt;&lt;/strong&gt;&quot;Expertus: A Generator Approach to Automate Performance Testing in IaaS Clouds&quot;, In &lt;em&gt;CLOUD 2012.&lt;/em&gt;&lt;a href=&quot;http://www-static.cc.gatech.edu/~qywang/papers/Cloud12Deepal.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Jack Li, Qingyang Wang, Yasuhiko Kanemasa, Deepal Jayasinghe, Simon Malkowski, Pengcheng Xiong, Motoyuki Kawaba and Calton Pu.&lt;/span&gt;&lt;/strong&gt;&quot;Profit-Based Experimental Analysis of IaaS Cloud Performance: Impact of Software Resource Allocation&quot;, In &lt;em&gt;SCC 2012.&lt;/em&gt;&lt;a href=&quot;http://www-static.cc.gatech.edu/~qywang/papers/SCC2012Jack.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Simon Malkowski, Yasuhiko Kanemasay, Hanwei Chen, Masao Yamamotoz, Qingyang Wang, Deepal Jayasinghe, Calton Pu, and Motoyuki Kawaba.&lt;/span&gt;&lt;/strong&gt;&quot;Challenges and Opportunities in Consolidation at High Resource Utilization: Non-monotonic Response Time Variations in n-Tier Applications&quot;, In &lt;em&gt;CLOUD 2012.&lt;/em&gt;&lt;a href=&quot;http://www-static.cc.gatech.edu/~qywang/papers/CLOUD12Simon.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2011&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Malkowski, S., Hedwig, M., Li, J., Pu, C., and Neumann, D.&lt;/b&gt; &quot;Automated Control for Elastic n-Tier Workloads based on Empirical Modeling&quot;&lt;i&gt; Proceedings of the 8th International Conference on Autonomic Computing. ACM.(ICAC 2011)&lt;/i&gt; Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/icac11-Malkowski.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Qingyang Wang, Simon Malkowski, Yasuhiko Kanemasa, Deepal Jayasinghe, Pengcheng Xiong, Calton Pu, Motoyuki Kawaba,Lilian Harada&lt;/span&gt;&lt;/strong&gt;, &quot;The Impact of Soft Resource Allocation on n-Tier Application Scalability&quot;, In &lt;em&gt;Proceedings of 25th IEEE International Symposium on Parallel and Distributed Processing (IPDPS'11)&lt;/em&gt;, May 2011.&lt;a href=&quot;http://www-static.cc.gatech.edu/~qywang/papers/IPDPS2011Wang.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Pengcheng Xiong, Yun Chi, Shenghuo Zhu, Junichi Tatemura, Calton Pu and Hakan Hacigumus&lt;/span&gt;&lt;/strong&gt;, &quot;ActiveSLA: A Profit-Oriented Admission Control Framework for Database-as-a-Service Providers&quot;, In &lt;em&gt;Proceedings of ACM Symposium on Cloud Computing (SOCC'11)&lt;/em&gt;, Oct. 2011.&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Pengcheng Xiong, Zhikui Wang, Simon Malkowski, Qingyang Wang, Deepal Jayasinghe and Calton Pu.&lt;/span&gt;&lt;/strong&gt; &quot;Economical and Robust Provisioning of N-Tier Cloud Workloads: A Multi-level Control Approach&quot;, In &lt;em&gt;Proceedings of IEEE International Conference On Distributed Computing Systems (ICDCS) (ICDCS'11)&lt;/em&gt;, June 2011.&lt;a href=&quot;http://www.cc.gatech.edu/~pxiong3/Papers/ICDCS2011.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Pengcheng Xiong, Yun Chi, Shenghuo Zhu, Hyun Jin Moon, Calton Pu and Hakan Hacigumus.&lt;/span&gt;&lt;/strong&gt; &quot;Intelligent Management of Virtualized Resources for Database Management Systems in Cloud Environment&quot;, In &lt;em&gt;IEEE International Conference on Data Engineering (ICDE'11)&lt;/em&gt;, April 2011.&lt;a href=&quot;http://www.cc.gatech.edu/~pxiong3/Papers/ICDE2011.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Deepal Jayasinghe, Simon Malkowski, Qingyang Wang, Jack Li, Pengcheng Xiong and Calton Pu.&lt;/span&gt;&lt;/strong&gt; &quot;Variations in Performance and Scalability when Migrating n-Tier Applications to Different Clouds&quot;, In &lt;em&gt;CLOUD 2011&lt;/em&gt; &lt;b&gt;[Best Student Paper Award].&lt;/b&gt; &lt;a href=&quot;http://www.cc.gatech.edu/grads/i/ijayasin/resources/ieee-cloud-2011.pdf&quot;&gt;[pdf]&lt;/a&gt;, &lt;a href=&quot;http://www.slideshare.net/deepalk/variations-in-performance-and-scalability-when-migrating-ntier-applications-to-different-clouds&quot;&gt;[ppt]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li class=&quot;level1&quot;&gt;
&lt;div class=&quot;li&quot;&gt;&lt;strong&gt;&lt;span class=&quot;search_hit&quot;&gt;Deepal Jayasinghe, Tamar Eilam (IBM Research), Malgorzata Steinder(IBM Research), Ian Whally(IBM Research), Ed Snible(IBM Research), and Calton Pu.&lt;/span&gt;&lt;/strong&gt; &quot;Improving Service Performance and Availability on Clouds with Structural Constraint-aware Virtual Machine Placement&quot;, &lt;em&gt;SCC 2011&lt;/em&gt;.&lt;a href=&quot;http://www.cc.gatech.edu/grads/i/ijayasin/resources/ieee-scc-2011.pdf&quot;&gt;[pdf]&lt;/a&gt;&lt;/div&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2010&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Malkowski, S., Hedwig, M., Jayasinghe, D., Pu, C., and Neumann, D.&lt;/b&gt;&quot;CloudXplor: A tool for configuration planning in clouds based on empirical data&quot;&lt;i&gt;Proceedings of the 25th Symposium On Applied Computing. ACM.(SAC 2010)&lt;/i&gt;Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/SAC2010_1.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Malkowski, S., Jayasinghe, D., Hedwig, M., Park, J., Kanemasa, Y., and Pu, C.&lt;/b&gt;&quot;Empirical analysis of database server scalability using an n-tier benchmark with read-intensive workload&quot;&lt;i&gt; Proceedings of the 25th Symposium On Applied Computing. ACM.(SAC2010)&lt;/i&gt; Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/SAC2010_2.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Xiong, P., Wang, z., Jung, G., and Pu, C.&lt;/b&gt;&quot;Study on performance management and application behavior in virtualized environment&quot;&lt;i&gt;Proceedings of the 12th Network Operation and Management Symposium (NOMS 2010)(short paper)&lt;/i&gt; Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/NOMS2010.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2009&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Malkowski, S., Hedwig, M., and Pu, C.&lt;/b&gt;&quot;Experimental evaluation of N-tier systems: Observation and analysis of multi-bottlenecks&quot;&lt;i&gt;Proceedings of the 2009 IEEE 12th International Symposium on Workload Characterization(IISWC 2009)&lt;/i&gt;, Austin, TX, USA. Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/IISWC09.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Malkowski, S., Hedwig, M., Jayasinghe, D., Park, J., Kanemasa, Y., and Pu, C.&lt;/b&gt;&quot;A new perspective on experimental analysis of n-tier systems: Evaluating database scalability, multi-bottlenecks, and economical operation&quot;&lt;i&gt;Proceedings of the 5th International Conference on Collaborative Computing: Networking, Applications, and Worksharing (CollaborateCom09)&lt;/i&gt;, Washington, DC, USA.. Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/CollaborateCom09.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Gueyoung Jung, Kaustubh Joshi, Matti Hiltunen, Richard Schlichting, and Calton Pu.&lt;/b&gt;&quot;A Cost-Sensitive Adaptation Engine for Server Consolidation of Multi-Tier Applications. &quot;&lt;i&gt;ACM/IFIP/USENIX 10th International Middleware Conference (Middleware 2009)&lt;/i&gt;, Nov. 30 - Dec. 4, 2009, Urbana Champaign, Illinois, USA.. Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/Middleware09.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Gueyoung Jung, Kaustubh Joshi, and Matti Hiltunen.&lt;/b&gt;&quot;Performance Aware Regeneration in Virtualized Multitier Applications. &quot;&lt;i&gt;Proactive Failure Avoidance Recovery and Maintenance (PFARM 2009)&lt;/i&gt;, June 29, 2009, Estoril, Lisbon, Portugal. Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/PFARM09.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2008&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Gueyoung Jung, Matti Hiltunen, Kaustubh Joshi, Richard Schlichting and Calton Pu.&lt;/b&gt;&quot;Generating Adaptation Policies for Multi-Tier Applications in Consolidated Server Environments. &quot;&lt;i&gt;IEEE International Conference on Autonomic Computing (ICAC 2008)&lt;/i&gt;, June 2-6, 2008, Chicago, IL. Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/ICAC08.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2007&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Simon Malkowski, Markus Hedwig, Jason Parekh, Calton Pu, and Akhil Sahai. &lt;/b&gt;&quot;Bottleneck Detection Using Statistical Intervention Analysis.&quot; &lt;i&gt;IFIP/IEEE Distributed Systems: Operations and Management (DSOM 2007)&lt;/i&gt; , October 29-31, 2007, San Jose, California, USA. Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/200710_DSOM07.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Calton Pu, Akhil Sahai, Jason Parekh, Gueyoung Jung, Ji Bae, You-Kyung Cha, Timothy Garcia, Danesh Irani, Jae Lee, Qifeng Lin.&lt;/b&gt; &quot;An Observation-Based Approach to Performance Characterization of Distributed n-Tier Applications.&quot; &lt;i&gt;IEEE International Symposium on Workload Characterization (IISWC 2007)&lt;/i&gt;, September 27-29, 2007, Four Point Sheraton Logan Airport, Boston, MA. Download:&lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/200709_iiswc07.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Qinyi Wu, Calton Pu, Akhil Sahai, Roger Barga.&lt;/b&gt; &quot;Categorization and Optimization of Synchronization Dependencies in Business Processes.&quot; &lt;i&gt;Proceedings of the IEEE 2007 International Conference on Data Engineering (ICDE'07)&lt;/i&gt;, Istambul, April 2007. Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/200704_Qinyi.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2006&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Gueyoung Jung, Galen Swint, Jason Parekh, Calton Pu, and Akhil Sahai.&lt;/b&gt;&quot;Detecting Bottleneck in n-Tier IT Applications through Analysis.&quot; &lt;i&gt;IFIP/IEEE Distributed Systems: Operations and Management (DSOM 2006)&lt;/i&gt;, October 23-25, 2006, Dublin, Ireland. Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/200610_dsom2006.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Qinyi Wu, Calton Pu, Akhil Sahai, Roger Barga, Gueyoung Jung, Jason Parekh, Galen Swint.&lt;/b&gt; &quot;DSCWeaver: Synchronization-Constraint Aspect Extension to Procedural Process Specification Languages.&quot; &lt;i&gt;IEEE International Conference on Web Services (ICWS 2006)&lt;/i&gt;, September 18-22, 2006, Chicago.Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/200609_ICWS_DSCWeaver.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Qinyi Wu, Calton Pu, Akhil Sahai.&lt;/b&gt; &quot;DAG Synchronization Constraint Language for Business Processes.&quot; &lt;i&gt;In Proceedings of IEEE Conference on ECommerce Technology (CEC'06)&lt;/i&gt;, June 26-29, 2006, San Francisco, California, USA. Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/200606_CEC_DSCL_Elba.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Jason Parekh, Gueyoung Jung, Galen Swint, Calton Pu, Akhil Sahai.&lt;/b&gt;&quot;Comparison of Performance Analysis Approaches for Bottleneck Detection in Multi-Tier Enterprise Applications.&quot; &lt;i&gt;IEEE International Workshop on Quality of Service&lt;/i&gt;, June 19-21, 2006, Yale University, New Haven, CT. Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/200606_IWQoS2006.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Galen Swint, Gueyoung Jung, Calton Pu, Akhil Sahai.&lt;/b&gt; &quot;Automated Staging for Built-to-Order Application Systems.&quot; &lt;i&gt;IFIP/IEEE Network Operations and Management Symposium (NOMS 2006)&lt;/i&gt;, April 2006, Vancouver, Canada. Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/200604_NOMS_mulini.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;2005&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Galen Swint, Calton Pu, Charles Consel, Gueyoung Jung, Akhil Sahai, Wenchang Yan, Younggyun Koh, Qinyi Wu. &lt;/b&gt;&quot;Clearwater - Extensible, Flexible, Modular Code Generation.&quot; &lt;i&gt;Proceedings of the 20th IEEE/ACM International Conference on Automated Software Engineering (ASE 2005)&lt;/i&gt;, November 7-11, 2005. Long Beach, California. Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/200511_ASE.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;ul&gt;
&lt;li&gt;&lt;b&gt;Sahai, Akhil, Calton Pu, Gueyoung Jung, Qinyi Wu, Wenchang Yan, Galen Swint. &lt;/b&gt;&quot;Towards Automated Deployment of Built-to-Order Systems.&quot; &lt;i&gt;Proceedings of the 16th IFIP/IEEE Distributed Systems; Operation and Management (DSOM 2005)&lt;/i&gt;, October 24-26, 2005. Barcelona, Spain. Download: &lt;a href=&quot;https://www.cc.gatech.edu/systems/projects/Elba/pub/200510_DSOM.pdf&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;[pdf]&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;</content><author><name>{&quot;login&quot;=&gt;&quot;gtelbaproject&quot;, &quot;email&quot;=&gt;&quot;gt.elba.project@gmail.com&quot;, &quot;display_name&quot;=&gt;&quot;GT Elba Project&quot;, &quot;first_name&quot;=&gt;&quot;GT Elba&quot;, &quot;last_name&quot;=&gt;&quot;Project&quot;}</name><email>gt.elba.project@gmail.com</email></author><summary type="html">2017 Qingyang Wang, Chien-An Lai, Yasuhiko Kanemasa, Shungeng Zhang, and Calton Pu “A Study of Long-Tail Latency in n-Tier Systems: RPC vs. Asynchronous Invocations”, In 37th International Conference on Distributed Computing Systems (ICDCS'17), Atlanta, GA, June 2017. (Acceptance rate: 90/531=16.9%) Chien-An Lai, Joshua Kimball, Tao Zhu, Qingyang Wang, and Calton Pu“milliScope: a Fine-Grained Monitoring Framework for Performance Debugging of n-Tier Web Services&quot;, In 37th International Conference on Distributed Computing Systems (ICDCS'17), Atlanta, GA, June 2017. (Acceptance rate: 90/531=16.9%) Tao Zhu, Jack Li, Josh Kimball, Junhee Park, Chien-An Lai, Calton Pu and Qingyang Wang &quot;Limitations of Load Balancing Mechanisms for N-Tier Systems in the Presence of Millibottlenecks&quot;, In 37th International Conference on Distributed Computing Systems (ICDCS'17), Atlanta, GA, June 2017. (Application track) 2016 Junhee Park, Qingyang Wang Jack Li, Chien-An Lai, Tao Zhu, Calton Pu“Performance Interference of Memory Thrashing in Virtualized Cloud Environments: A Study of consolidated n-Tier Applications”, In Proc. of the 9th International Conference On Cloud Computing (Cloud'16). (Acceptance rate: 15%) (Runner-Up for Best Paper Award) 2015 Jack Li, Yuan Chen, Vanish Talwar, Calton Pu, Dejan Milojicic, &quot;Improving Preemptive Scheduling with Application-Transparent Checkpointing in Shared Clusters&quot;, In Middleware 2015. [tbd] 2014 Jack Li, Qingyang Wang, Chien-An Lai, Junhee Park, Daisuke Yokoyama, Calton Pu, &quot;The Impact of Software Resource Allocation on Consolidated n-Tier Applications&quot;, In CLOUD 2014. Qingyang Wang, Jack Li, Chien-An Lai, Chien-An Cho, Yuji Nomura, Calton Pu&quot;Lightning in the Cloud: A Study of Transient Bottlenecks on n-Tier Web Application Performance&quot;, In TRIOS 2014. Chien-An Lai, Qingyang Wang, Josh Kimball, Jack Li, Junhee Park, Calton Pu, &quot;IO Performance Interference among Consolidated n-Tier Applications: Sharing Is Better Than Isolation for Disks&quot;, In CLOUD 2014. 2013 Qingyang Wang, Yasuhiko Kanemasa, Jack Li, Chien An Lai, Masazumi Matsubara, Calton Pu, &quot;Impact of DVFS on n-Tier Application Performance&quot;, In Proc. of ACM Conference on Timely Results in Operating Systems (TRIOS'13), Nemacolin Woodlands Resort, Farmington, Pennsylvania, November 2013. [pdf] Qingyang Wang, Yasuhiko Kanemasa, Jack Li, Deepal Jayasinghe, Toshihiro Shimizu, Masazumi Matsubara, Motoyuki Kawaba, Calton Pu. &quot;Detecting Transient Bottlenecks in n-Tier Applications through Fine-Grained Analysis&quot;, In ICDCS 2013.[pdf] Qingyang Wang, Yasuhiko Kanemasa, Jack Li, Deepal Jayasinghe, Toshihiro Shimizu, Masazumi Matsubara, Motoyuki Kawaba, Calton Pu. &quot;An Experimental Study of Rapidly Alternating Bottlenecks in n-Tier Applications&quot;, In Cloud 2013.(Runner-Up for Best Student Paper Award).[pdf] Deepal Jayasinghe, Fabio Oliveira, Florian Rosenberg, Tamar Eilam, Calton Pu. &quot;AESON: A Model-Driven and Fault Tolerant Composite Deployment Runtime for IaaS Clouds&quot;, In SCC 2013.[pdf] Deepal Jayasinghe, Josh Kimball, Tao Zhu, Siddharth Choudhary, Calton Pu. &quot;An Infrastructure for Automating Large-scale Performance Studies and Data Processing&quot;, In BigData 2013.[pdf] Deepal Jayasinghe, Josh Kimball, Siddharth Choudhary, Tao Zhu, Calton Pu. &quot;An Automated Approach to Create, Store, and Analyze Large-scale Experimental Data in Clouds&quot;, In IRI 2013.(Best Student Paper Award).[pdf] Junhee Park, Qingyang Wang, Deepal Jayasinghe, Jack Li, Yasuhiko Kanemasa, Masazumi Matsubara, Calton Pu. &quot;Variations in Performance Measurements of Multi-Core Processors: A Study of n-Tier Applications&quot;, In SCC 2013.[pdf] Jack Li, Qingyang Wang, Deepal Jayasinghe, Junhee Park, Tao Zhu, Calton Pu. &quot;Performance Overhead Among Three Hypervisors: An Experimental Study using Hadoop Benchmarks&quot;, In BigData Congress 2013.[pdf] Yasuhiko Kanemasa, Qingyang Wang, Jack Li, Masazumi Matsubara, Calton Pu. &quot;Revisiting Performance Interference among Consolidated n-Tier Applications: Sharing is Better than Isolation&quot;, In SCC 2013.[pdf] 2012 Qingyang Wang, Yasuhiko Kanemasa, Motoyuki Kawaba, Calton Pu.&quot;When Average is Not Average: Large Response Time Fluctuations in n-Tier Systems&quot;, In ICAC 2012.[pdf] Qingyang Wang, Yasuhiko Kanemasa, Jack Li, Deepal Jayasinghe, Motoyuki Kawaba, Calton Pu&quot;Response Time Reliability in Cloud Environments: An Empirical Study of n-Tier Applications at High Resource Utilization&quot;, In SRDS 2012.[pdf] Deepal Jayasinghe, Galen Swint, Simon Malkowski, Jack Li, Qingyang Wang, Junhee Park and Calton Pu.&quot;Expertus: A Generator Approach to Automate Performance Testing in IaaS Clouds&quot;, In CLOUD 2012.[pdf] Jack Li, Qingyang Wang, Yasuhiko Kanemasa, Deepal Jayasinghe, Simon Malkowski, Pengcheng Xiong, Motoyuki Kawaba and Calton Pu.&quot;Profit-Based Experimental Analysis of IaaS Cloud Performance: Impact of Software Resource Allocation&quot;, In SCC 2012.[pdf] Simon Malkowski, Yasuhiko Kanemasay, Hanwei Chen, Masao Yamamotoz, Qingyang Wang, Deepal Jayasinghe, Calton Pu, and Motoyuki Kawaba.&quot;Challenges and Opportunities in Consolidation at High Resource Utilization: Non-monotonic Response Time Variations in n-Tier Applications&quot;, In CLOUD 2012.[pdf] 2011 Malkowski, S., Hedwig, M., Li, J., Pu, C., and Neumann, D. &quot;Automated Control for Elastic n-Tier Workloads based on Empirical Modeling&quot; Proceedings of the 8th International Conference on Autonomic Computing. ACM.(ICAC 2011) Download: [pdf] Qingyang Wang, Simon Malkowski, Yasuhiko Kanemasa, Deepal Jayasinghe, Pengcheng Xiong, Calton Pu, Motoyuki Kawaba,Lilian Harada, &quot;The Impact of Soft Resource Allocation on n-Tier Application Scalability&quot;, In Proceedings of 25th IEEE International Symposium on Parallel and Distributed Processing (IPDPS'11), May 2011.[pdf] Pengcheng Xiong, Yun Chi, Shenghuo Zhu, Junichi Tatemura, Calton Pu and Hakan Hacigumus, &quot;ActiveSLA: A Profit-Oriented Admission Control Framework for Database-as-a-Service Providers&quot;, In Proceedings of ACM Symposium on Cloud Computing (SOCC'11), Oct. 2011. Pengcheng Xiong, Zhikui Wang, Simon Malkowski, Qingyang Wang, Deepal Jayasinghe and Calton Pu. &quot;Economical and Robust Provisioning of N-Tier Cloud Workloads: A Multi-level Control Approach&quot;, In Proceedings of IEEE International Conference On Distributed Computing Systems (ICDCS) (ICDCS'11), June 2011.[pdf] Pengcheng Xiong, Yun Chi, Shenghuo Zhu, Hyun Jin Moon, Calton Pu and Hakan Hacigumus. &quot;Intelligent Management of Virtualized Resources for Database Management Systems in Cloud Environment&quot;, In IEEE International Conference on Data Engineering (ICDE'11), April 2011.[pdf] Deepal Jayasinghe, Simon Malkowski, Qingyang Wang, Jack Li, Pengcheng Xiong and Calton Pu. &quot;Variations in Performance and Scalability when Migrating n-Tier Applications to Different Clouds&quot;, In CLOUD 2011 [Best Student Paper Award]. [pdf], [ppt] Deepal Jayasinghe, Tamar Eilam (IBM Research), Malgorzata Steinder(IBM Research), Ian Whally(IBM Research), Ed Snible(IBM Research), and Calton Pu. &quot;Improving Service Performance and Availability on Clouds with Structural Constraint-aware Virtual Machine Placement&quot;, SCC 2011.[pdf] 2010 Malkowski, S., Hedwig, M., Jayasinghe, D., Pu, C., and Neumann, D.&quot;CloudXplor: A tool for configuration planning in clouds based on empirical data&quot;Proceedings of the 25th Symposium On Applied Computing. ACM.(SAC 2010)Download: [pdf] Malkowski, S., Jayasinghe, D., Hedwig, M., Park, J., Kanemasa, Y., and Pu, C.&quot;Empirical analysis of database server scalability using an n-tier benchmark with read-intensive workload&quot; Proceedings of the 25th Symposium On Applied Computing. ACM.(SAC2010) Download: [pdf] Xiong, P., Wang, z., Jung, G., and Pu, C.&quot;Study on performance management and application behavior in virtualized environment&quot;Proceedings of the 12th Network Operation and Management Symposium (NOMS 2010)(short paper) Download: [pdf] 2009 Malkowski, S., Hedwig, M., and Pu, C.&quot;Experimental evaluation of N-tier systems: Observation and analysis of multi-bottlenecks&quot;Proceedings of the 2009 IEEE 12th International Symposium on Workload Characterization(IISWC 2009), Austin, TX, USA. Download: [pdf] Malkowski, S., Hedwig, M., Jayasinghe, D., Park, J., Kanemasa, Y., and Pu, C.&quot;A new perspective on experimental analysis of n-tier systems: Evaluating database scalability, multi-bottlenecks, and economical operation&quot;Proceedings of the 5th International Conference on Collaborative Computing: Networking, Applications, and Worksharing (CollaborateCom09), Washington, DC, USA.. Download: [pdf] Gueyoung Jung, Kaustubh Joshi, Matti Hiltunen, Richard Schlichting, and Calton Pu.&quot;A Cost-Sensitive Adaptation Engine for Server Consolidation of Multi-Tier Applications. &quot;ACM/IFIP/USENIX 10th International Middleware Conference (Middleware 2009), Nov. 30 - Dec. 4, 2009, Urbana Champaign, Illinois, USA.. Download: [pdf] Gueyoung Jung, Kaustubh Joshi, and Matti Hiltunen.&quot;Performance Aware Regeneration in Virtualized Multitier Applications. &quot;Proactive Failure Avoidance Recovery and Maintenance (PFARM 2009), June 29, 2009, Estoril, Lisbon, Portugal. Download: [pdf] 2008 Gueyoung Jung, Matti Hiltunen, Kaustubh Joshi, Richard Schlichting and Calton Pu.&quot;Generating Adaptation Policies for Multi-Tier Applications in Consolidated Server Environments. &quot;IEEE International Conference on Autonomic Computing (ICAC 2008), June 2-6, 2008, Chicago, IL. Download: [pdf] 2007 Simon Malkowski, Markus Hedwig, Jason Parekh, Calton Pu, and Akhil Sahai. &quot;Bottleneck Detection Using Statistical Intervention Analysis.&quot; IFIP/IEEE Distributed Systems: Operations and Management (DSOM 2007) , October 29-31, 2007, San Jose, California, USA. Download: [pdf] Calton Pu, Akhil Sahai, Jason Parekh, Gueyoung Jung, Ji Bae, You-Kyung Cha, Timothy Garcia, Danesh Irani, Jae Lee, Qifeng Lin. &quot;An Observation-Based Approach to Performance Characterization of Distributed n-Tier Applications.&quot; IEEE International Symposium on Workload Characterization (IISWC 2007), September 27-29, 2007, Four Point Sheraton Logan Airport, Boston, MA. Download:[pdf] Qinyi Wu, Calton Pu, Akhil Sahai, Roger Barga. &quot;Categorization and Optimization of Synchronization Dependencies in Business Processes.&quot; Proceedings of the IEEE 2007 International Conference on Data Engineering (ICDE'07), Istambul, April 2007. Download: [pdf] 2006 Gueyoung Jung, Galen Swint, Jason Parekh, Calton Pu, and Akhil Sahai.&quot;Detecting Bottleneck in n-Tier IT Applications through Analysis.&quot; IFIP/IEEE Distributed Systems: Operations and Management (DSOM 2006), October 23-25, 2006, Dublin, Ireland. Download: [pdf] Qinyi Wu, Calton Pu, Akhil Sahai, Roger Barga, Gueyoung Jung, Jason Parekh, Galen Swint. &quot;DSCWeaver: Synchronization-Constraint Aspect Extension to Procedural Process Specification Languages.&quot; IEEE International Conference on Web Services (ICWS 2006), September 18-22, 2006, Chicago.Download: [pdf] Qinyi Wu, Calton Pu, Akhil Sahai. &quot;DAG Synchronization Constraint Language for Business Processes.&quot; In Proceedings of IEEE Conference on ECommerce Technology (CEC'06), June 26-29, 2006, San Francisco, California, USA. Download: [pdf] Jason Parekh, Gueyoung Jung, Galen Swint, Calton Pu, Akhil Sahai.&quot;Comparison of Performance Analysis Approaches for Bottleneck Detection in Multi-Tier Enterprise Applications.&quot; IEEE International Workshop on Quality of Service, June 19-21, 2006, Yale University, New Haven, CT. Download: [pdf] Galen Swint, Gueyoung Jung, Calton Pu, Akhil Sahai. &quot;Automated Staging for Built-to-Order Application Systems.&quot; IFIP/IEEE Network Operations and Management Symposium (NOMS 2006), April 2006, Vancouver, Canada. Download: [pdf] 2005 Galen Swint, Calton Pu, Charles Consel, Gueyoung Jung, Akhil Sahai, Wenchang Yan, Younggyun Koh, Qinyi Wu. &quot;Clearwater - Extensible, Flexible, Modular Code Generation.&quot; Proceedings of the 20th IEEE/ACM International Conference on Automated Software Engineering (ASE 2005), November 7-11, 2005. Long Beach, California. Download: [pdf] Sahai, Akhil, Calton Pu, Gueyoung Jung, Qinyi Wu, Wenchang Yan, Galen Swint. &quot;Towards Automated Deployment of Built-to-Order Systems.&quot; Proceedings of the 16th IFIP/IEEE Distributed Systems; Operation and Management (DSOM 2005), October 24-26, 2005. Barcelona, Spain. Download: [pdf]</summary></entry></feed>